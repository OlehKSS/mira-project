{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-atlas Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/okozyn/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isdir, join\n",
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from numpy.linalg import inv, det, norm\n",
    "from math import sqrt, pi\n",
    "from functools import partial\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"./src/nib-tools.py\"\n",
    "%run \"./src/file-tools.py\"\n",
    "%run \"./src/em.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Weights from Mutual Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['IBSR_18', 'IBSR_03', 'IBSR_01', 'IBSR_06', 'IBSR_09', 'IBSR_07', 'IBSR_16', 'IBSR_08', 'IBSR_05', 'IBSR_04']\n",
      "['IBSR_13', 'IBSR_12', 'IBSR_17', 'IBSR_11', 'IBSR_14']\n"
     ]
    }
   ],
   "source": [
    "# Path to test image\n",
    "valid_img_path = \"./registered-data/Par0009-matched-to-mni/Validation_Set/templates/\"\n",
    "gt_path = \"./registered-data/Par0009-matched-to-mni/Validation_Set/labels/\"\n",
    "train_labels_path = \"./registered-data/Par0009-matched-to-mni/Training_Set/labels/\"\n",
    "train_img_path = \"./registered-data/Par0009-matched-to-mni/Training_Set/templates/\"\n",
    "\n",
    "train_dirs = [f for f in listdir(train_img_path) if isdir(join(train_img_path, f))]\n",
    "valid_dirs = [f for f in listdir(valid_img_path) if isdir(join(valid_img_path, f))]\n",
    "\n",
    "# read training labels\n",
    "train_labels = []\n",
    "for f in train_dirs:\n",
    "    labels, _ = read_im(join(train_labels_path, f, 'result.nii.gz'))\n",
    "    train_labels.append(labels)\n",
    "\n",
    "print(train_dirs)\n",
    "print(valid_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sim_metrics(train_dir_path):\n",
    "    \"\"\"\n",
    "    Get similarity metrics from elastix log files.\n",
    "    \n",
    "    Args:\n",
    "        train_dir_path (str): the path to a folder with registration results.\n",
    "    \n",
    "    Returns:\n",
    "        (numpy.ndarray): similarity metrics.\n",
    "    \"\"\"\n",
    "    import re\n",
    "    \n",
    "    dirs = tuple(f for f in listdir(train_dir_path) if isdir(join(train_dir_path, f)))\n",
    "    sim_metrics = np.zeros(len(dirs))\n",
    "    \n",
    "    for index, train_dir in enumerate(dirs):\n",
    "        elastix_log_file = open(join(train_dir_path, train_dir, 'elastix.log'), \"r\")\n",
    "        elastix_log = elastix_log_file.read()\n",
    "        elastix_log_file.close()\n",
    "        reg_expr = r'^Final metric value\\s+=\\s+([\\d\\.\\-]+)$'\n",
    "        \n",
    "        matches = re.findall(reg_expr, elastix_log, re.M)\n",
    "        \n",
    "        # 0th value - MI after affine transformation, 1st value - MI after B-splines transformation\n",
    "        sim_metrics[index] = matches[1]\n",
    "        \n",
    "    return sim_metrics\n",
    "\n",
    "\n",
    "def majority_vote_masks(train_labels, weights=None):\n",
    "    \"\"\"\n",
    "    Get segmentation masks for CSF, GM, WM tissues.\n",
    "    \n",
    "    Args:\n",
    "        train_labels ([numpy.ndarray]): an iterable of training labels (ground-truth segmentations).\n",
    "        weights ([float]): an iterable with weights for each label, should have the same length\n",
    "            as train_labels, optional.\n",
    "    \n",
    "    Returns:\n",
    "        csf_mask, gm_mask, wm_mask (tuple(numpy.ndarray)): a tuple of masks for tissue segmentation.\n",
    "    \"\"\"\n",
    "    csf_mask = None\n",
    "    gm_mask = None\n",
    "    wm_mask = None\n",
    "    \n",
    "    if weights is None:\n",
    "        weights = np.ones(len(train_labels))\n",
    "\n",
    "    for labels, w in zip(train_labels, weights):\n",
    "        csf_vote = np.zeros_like(labels, dtype=float)\n",
    "        gm_vote = np.zeros_like(labels, dtype=float)\n",
    "        wm_vote = np.zeros_like(labels, dtype=float)\n",
    "\n",
    "        csf_vote[labels == CSF_label] = w\n",
    "        gm_vote[labels == GM_label] = w\n",
    "        wm_vote[labels == WM_label] = w\n",
    "\n",
    "        if (csf_mask is None) and (gm_mask is None) and (wm_mask is None):\n",
    "            csf_mask = csf_vote\n",
    "            gm_mask = gm_vote\n",
    "            wm_mask = wm_vote\n",
    "        else:\n",
    "            csf_mask += csf_vote\n",
    "            gm_mask += gm_vote\n",
    "            wm_mask += wm_vote\n",
    "    \n",
    "    return csf_mask, gm_mask, wm_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_metrics = get_sim_metrics(train_img_path)\n",
    "sim_metrics = -1 * sim_metrics\n",
    "maj_vote_csf_mask, maj_vote_gm_mask, maj_vote_wm_mask = majority_vote_masks(train_labels)#, weights=sim_metrics)\n",
    "\n",
    "CSF_atlas = normalize(maj_vote_csf_mask, max_val=1.0)\n",
    "GM_atlas = normalize(maj_vote_gm_mask, max_val=1.0)\n",
    "WM_atlas = normalize(maj_vote_wm_mask, max_val=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EM+Multi-atlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_intens = 255\n",
    "\n",
    "MAX_STEPS = 30\n",
    "min_change = 0.01\n",
    "\n",
    "test_img_path = valid_img_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************\n",
      "Img IBSR_13\n",
      "Step 0\n",
      "Distribution change 0.025566\n",
      "0.013099336726753747 0.4504321428358337 0.5364685204403042\n",
      "********************************************************************\n",
      "Img IBSR_13\n",
      "Step 1\n",
      "Distribution change 0.016794\n",
      "0.018664028062159176 0.5770037502991612 0.40433222163661403\n",
      "********************************************************************\n",
      "Img IBSR_13\n",
      "Step 2\n",
      "Distribution change 0.012760\n",
      "0.025198431441216203 0.6838181712308438 0.29098339732916906\n",
      "********************************************************************\n",
      "Img IBSR_13\n",
      "Step 3\n",
      "Distribution change 0.008638\n",
      "0.031220877090404168 0.7614755062031549 0.20730361670700584\n",
      "Loop stopped\n",
      "********************************************************************\n",
      "Img IBSR_12\n",
      "Step 0\n",
      "Distribution change 0.024910\n",
      "0.009691647678175841 0.471273627112572 0.5190347252069643\n",
      "********************************************************************\n",
      "Img IBSR_12\n",
      "Step 1\n",
      "Distribution change 0.013730\n",
      "0.011519289494660656 0.5869028243137014 0.4015778861929647\n",
      "********************************************************************\n",
      "Img IBSR_12\n",
      "Step 2\n",
      "Distribution change 0.008857\n",
      "0.015413303770498142 0.6712087917073565 0.3133779045222033\n",
      "Loop stopped\n",
      "********************************************************************\n",
      "Img IBSR_17\n",
      "Step 0\n",
      "Distribution change 0.015891\n",
      "0.007773378018563834 0.41452890569926404 0.5776977162840355\n",
      "********************************************************************\n",
      "Img IBSR_17\n",
      "Step 1\n",
      "Distribution change 0.006994\n",
      "0.007946868538282385 0.497572154226015 0.4944809772386741\n",
      "Loop stopped\n",
      "********************************************************************\n",
      "Img IBSR_11\n",
      "Step 0\n",
      "Distribution change 0.033259\n",
      "0.009997501934809302 0.4826055936114771 0.5073969044556635\n",
      "********************************************************************\n",
      "Img IBSR_11\n",
      "Step 1\n",
      "Distribution change 0.012109\n",
      "0.012260431891437032 0.6064942211257377 0.3812453469821603\n",
      "********************************************************************\n",
      "Img IBSR_11\n",
      "Step 2\n",
      "Distribution change 0.005853\n",
      "0.017853125770039432 0.6762175497156824 0.3059293245128286\n",
      "Loop stopped\n",
      "********************************************************************\n",
      "Img IBSR_14\n",
      "Step 0\n",
      "Distribution change 0.018910\n",
      "0.013549970812804955 0.4296759580800662 0.5567740711062633\n",
      "********************************************************************\n",
      "Img IBSR_14\n",
      "Step 1\n",
      "Distribution change 0.016284\n",
      "0.02191540991521273 0.5362850932078431 0.44179949687568426\n",
      "********************************************************************\n",
      "Img IBSR_14\n",
      "Step 2\n",
      "Distribution change 0.014235\n",
      "0.03427412419044013 0.6394750104200068 0.32625086538920983\n",
      "********************************************************************\n",
      "Img IBSR_14\n",
      "Step 3\n",
      "Distribution change 0.009984\n",
      "0.04773611406029311 0.7189206491913483 0.23334323675070648\n",
      "Loop stopped\n"
     ]
    }
   ],
   "source": [
    "# Path to atlas image folder\n",
    "atlas_path = \"./atlases/Par0009-no-matching/\"\n",
    "result_path = \"./segmentation-results/Par0009-no-matching/em-segmentation/\"\n",
    "out_dice_path = './dice-results/Par0009_no_matching_em_dice.csv'\n",
    "#os.mkdir(result_path)\n",
    "\n",
    "onlydirs = [f for f in listdir(test_img_path) if isdir(join(test_img_path, f))]\n",
    "\n",
    "all_dice = np.zeros((len(onlydirs),3))\n",
    "\n",
    "GM_atlas_flat = GM_atlas.flatten()\n",
    "WM_atlas_flat = WM_atlas.flatten()\n",
    "CSF_atlas_flat = CSF_atlas.flatten()\n",
    "mask = GM_atlas + WM_atlas + CSF_atlas\n",
    "mask_data = mask.copy().flatten()\n",
    "mask_data = np.transpose(mask_data)\n",
    "\n",
    "for i, f in enumerate(onlydirs):\n",
    "    # Load all data for EM algorithm\n",
    "    test_data, test_img = read_im(join(test_img_path, f, 'result.1.nii.gz'))\n",
    "    test_data = normalize(test_data, max_intens)\n",
    "\n",
    "    _, groundtruth_img = read_im(join(gt_path, f, \"result.nii.gz\"))\n",
    "\n",
    "    # Pre-process feature vector to remove background points from algorithm\n",
    "    # and save those indicies to add back\n",
    "    features = test_data.copy().flatten()\n",
    "    features = np.transpose(features)   \n",
    "\n",
    "    features_nonzero_row_indicies = np.nonzero(mask_data)\n",
    "    features_nonzero = features[features_nonzero_row_indicies]\n",
    "\n",
    "    # row index shifted by +1 will correspond to tissue labels from ground-truth\n",
    "    features_nonzero_pred = np.array((CSF_atlas_flat[features_nonzero_row_indicies],\n",
    "                                      WM_atlas_flat[features_nonzero_row_indicies],\n",
    "                                      GM_atlas_flat[features_nonzero_row_indicies]))\n",
    "    y_pred = np.argmax(features_nonzero_pred, axis=0)\n",
    "\n",
    "    # intialize EM algorithm\n",
    "    class0 = features_nonzero[np.argwhere(y_pred == 0)[:,0]]\n",
    "    class1 = features_nonzero[np.argwhere(y_pred == 1)[:,0]]\n",
    "    class2 = features_nonzero[np.argwhere(y_pred == 2)[:,0]]\n",
    "\n",
    "    # Compute mean and variance of each class\n",
    "    mean0 = np.mean(class0, axis = 0)\n",
    "    mean1 = np.mean(class1, axis = 0)\n",
    "    mean2 = np.mean(class2, axis = 0)\n",
    "    cov0 = np.cov(class0, rowvar = False)\n",
    "    cov1 = np.cov(class1, rowvar = False)\n",
    "    cov2 = np.cov(class2, rowvar = False)\n",
    "\n",
    "    # Class distribution\n",
    "    a0 = class0.shape[0] / features_nonzero.shape[0]\n",
    "    a1 = class1.shape[0] / features_nonzero.shape[0]\n",
    "    a2 = class2.shape[0] / features_nonzero.shape[0]\n",
    "\n",
    "    # Compute Gaussian mixture model for each point\n",
    "    p0 = gaussian_mixture(features_nonzero,  mean = mean0, cov = cov0)\n",
    "    p1 = gaussian_mixture(features_nonzero,  mean = mean1, cov = cov1)\n",
    "    p2 = gaussian_mixture(features_nonzero,  mean = mean2, cov = cov2)\n",
    "\n",
    "    # # Compute membership weight for each point\n",
    "    weights = membership_weight(p0, p1, p2, a0, a1, a2)\n",
    "    # get initial log-likelihood\n",
    "    log_likelihood = get_log_likelihood((a0, a1, a2), (p0, p1, p2))\n",
    "\n",
    "    n_steps = 0\n",
    "\n",
    "    while True:\n",
    "        # Maximization step: Use that classification to reestimate the parameters\n",
    "        # Class distribution\n",
    "        counts = np.sum(weights, axis=0)\n",
    "\n",
    "        a0 = counts[0] / len(features_nonzero)\n",
    "        a1 = counts[1] / len(features_nonzero)\n",
    "        a2 = counts[2] / len(features_nonzero)\n",
    "\n",
    "        # Calculate mean and covariance for new classes\n",
    "        mean0 = (1/counts[0]) * (weights[:, 0] @ features_nonzero)\n",
    "        mean1 = (1/counts[1]) * (weights[:, 1] @ features_nonzero)\n",
    "        mean2 = (1/counts[2]) * (weights[:, 2] @ features_nonzero)\n",
    "        cov0 = (1/counts[0]) * ((weights[:, 0] * (features_nonzero - mean0)) @ (features_nonzero - mean0))\n",
    "        cov1 = (1/counts[1]) * ((weights[:, 1] * (features_nonzero - mean1)) @ (features_nonzero - mean1))\n",
    "        cov2 = (1/counts[2]) * ((weights[:, 2] * (features_nonzero - mean2)) @ (features_nonzero - mean2))\n",
    "\n",
    "        p0 = gaussian_mixture(features_nonzero,  mean = mean0, cov = cov0)\n",
    "        p1 = gaussian_mixture(features_nonzero,  mean = mean1, cov = cov1)\n",
    "        p2 = gaussian_mixture(features_nonzero,  mean = mean2, cov = cov2)\n",
    "\n",
    "        # Compute membership weight for each point\n",
    "        weights = membership_weight(p0, p1, p2, a0, a1, a2)\n",
    "\n",
    "        log_likelihood_new = get_log_likelihood((a0, a1, a2), (p0, p1, p2))\n",
    "\n",
    "        dist_change = abs((log_likelihood_new - log_likelihood) / log_likelihood)\n",
    "        print(\"********************************************************************\")\n",
    "        print(f\"Img {f}\")\n",
    "        print(\"Step %d\" % n_steps)\n",
    "        print(\"Distribution change %f\" % dist_change)\n",
    "        print(a0, a1, a2)\n",
    "\n",
    "        n_steps += 1\n",
    "\n",
    "        # check whether we reached desired precision or max number of steps\n",
    "        if (n_steps >= MAX_STEPS) or (dist_change <= min_change):\n",
    "            print(\"Loop stopped\")\n",
    "            break\n",
    "        else:\n",
    "            log_likelihood = log_likelihood_new\n",
    "\n",
    "    y_pred = np.argmax(weights, axis=1)\n",
    "    segment_nii_atlas = integrate_atlas_nii(test_img, y_pred, features_nonzero, \n",
    "                               features_nonzero_row_indicies, weights, CSF_atlas, \n",
    "                               GM_atlas, WM_atlas)\n",
    "\n",
    "    # Calculate DICE\n",
    "    all_dice[i,0], all_dice[i,1], all_dice[i,2] = dice_similarity(segment_nii_atlas, groundtruth_img)\n",
    "\n",
    "    # Make directory to save result seg\n",
    "   # new_dir = join(result_path,f)\n",
    "    #os.mkdir(new_dir)\n",
    "    #nib.save(segment_nii_atlas, join(new_dir,'atlas_EM_seg.nii.gz'))\n",
    "\n",
    "save_dice(out_dice_path, onlydirs, all_dice)\n",
    "# print(np.mean(all_dice, axis=0))\n",
    "# all_dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.73815124 0.8157114  0.80473421]\n",
      " [0.85011393 0.78033749 0.82912281]\n",
      " [0.86132058 0.79138092 0.80600781]\n",
      " [0.86190173 0.76952285 0.82103951]\n",
      " [0.79405735 0.80653402 0.82950308]]\n",
      "[0.82110897 0.79269734 0.81808148]\n"
     ]
    }
   ],
   "source": [
    "# experiments with weighted multi-atlas\n",
    "print(all_dice)\n",
    "print(np.mean(all_dice, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.72695911 0.80754481 0.81038132]\n",
      " [0.84551396 0.77880952 0.82519491]\n",
      " [0.86380167 0.82515532 0.8185299 ]\n",
      " [0.86042216 0.76879285 0.81650924]\n",
      " [0.82544768 0.80115997 0.82965957]]\n",
      "[0.82442892 0.7962925  0.82005499]\n"
     ]
    }
   ],
   "source": [
    "# experiments with multi-atlas\n",
    "print(all_dice)\n",
    "print(np.mean(all_dice, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
